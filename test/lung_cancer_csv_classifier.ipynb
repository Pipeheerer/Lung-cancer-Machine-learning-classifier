{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step - 1: Imporing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step - 2 : Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(309, 16)\n",
      "  GENDER  AGE  SMOKING  YELLOW_FINGERS  ANXIETY  PEER_PRESSURE  \\\n",
      "0      M   69        1               2        2              1   \n",
      "1      M   74        2               1        1              1   \n",
      "2      F   59        1               1        1              2   \n",
      "3      M   63        2               2        2              1   \n",
      "4      F   63        1               2        1              1   \n",
      "\n",
      "   CHRONIC DISEASE  FATIGUE   ALLERGY   WHEEZING  ALCOHOL CONSUMING  COUGHING  \\\n",
      "0                1         2         1         2                  2         2   \n",
      "1                2         2         2         1                  1         1   \n",
      "2                1         2         1         2                  1         2   \n",
      "3                1         1         1         1                  2         1   \n",
      "4                1         1         1         2                  1         2   \n",
      "\n",
      "   SHORTNESS OF BREATH  SWALLOWING DIFFICULTY  CHEST PAIN LUNG_CANCER  \n",
      "0                    2                      2           2         YES  \n",
      "1                    2                      2           2         YES  \n",
      "2                    2                      1           2          NO  \n",
      "3                    1                      2           2          NO  \n",
      "4                    2                      1           1          NO  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../datasets/LungCancer_CSVDataset/survey lung cancer.csv\")\n",
    "print(data.shape)\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns\n",
    "data[\"GENDER\"] = data[\"GENDER\"].map({\"M\": 1, \"F\": 0})\n",
    "data[\"LUNG_CANCER\"] = data[\"LUNG_CANCER\"].map({\"YES\": 1, \"NO\": 0})\n",
    "\n",
    "# Splitting dataset\n",
    "X = data.drop(\"LUNG_CANCER\", axis=1)\n",
    "y = data[\"LUNG_CANCER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize age and other numerical features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split train/test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to tensors for PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/scaler.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, \"../models/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step - 3: Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple PyTorch Model (MLP)\n",
    "class CancerNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CancerNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train.shape[1], 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "model = CancerNN()\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step - 5: Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.4737773835659027\n",
      "Epoch 20, Loss: 0.2655992805957794\n",
      "Epoch 30, Loss: 0.1889576017856598\n",
      "Epoch 40, Loss: 0.15550854802131653\n",
      "Epoch 50, Loss: 0.12664391100406647\n",
      "Epoch 60, Loss: 0.10489054024219513\n",
      "Epoch 70, Loss: 0.09095268696546555\n",
      "Epoch 80, Loss: 0.080286405980587\n",
      "Epoch 90, Loss: 0.07306680083274841\n",
      "Epoch 100, Loss: 0.0676325261592865\n"
     ]
    }
   ],
   "source": [
    "# Training the Neural Network\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step - 6: Evaluation of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test_tensor)\n",
    "    predictions = (test_outputs > 0.5).float()\n",
    "    accuracy = accuracy_score(y_test_tensor.numpy(), predictions.numpy())\n",
    "    print(f\"Neural Network Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step - 7: Building Secondary Learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Machine Learning Models\n",
    "rf = RandomForestClassifier(n_estimators=50)\n",
    "gb = GradientBoostingClassifier(n_estimators=50)\n",
    "ada = AdaBoostClassifier(n_estimators=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "gb.fit(X_train, y_train)\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "rf_pred = rf.predict(X_test)\n",
    "gb_pred = gb.predict(X_test)\n",
    "ada_pred = ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average the predictions (Ensemble)\n",
    "ensemble_pred = (rf_pred + gb_pred + ada_pred) / 3\n",
    "ensemble_pred = np.round(ensemble_pred)  # Convert to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "gb_acc = accuracy_score(y_test, gb_pred)\n",
    "ada_acc = accuracy_score(y_test, ada_pred)\n",
    "ensemble_acc = accuracy_score(y_test, ensemble_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.97\n",
      "Gradient Boosting Accuracy: 0.97\n",
      "AdaBoost Accuracy: 0.98\n",
      "Ensemble Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(f\"Random Forest Accuracy: {rf_acc:.2f}\")\n",
    "print(f\"Gradient Boosting Accuracy: {gb_acc:.2f}\")\n",
    "print(f\"AdaBoost Accuracy: {ada_acc:.2f}\")\n",
    "print(f\"Ensemble Accuracy: {ensemble_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step - 8: Deployment and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../models/cancer_detector.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/adaboost.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(rf, \"../models/random_forest.pkl\")\n",
    "joblib.dump(gb, \"../models/gradient_boosting.pkl\")\n",
    "joblib.dump(ada, \"../models/adaboost.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CancerNN(\n",
      "  (fc1): Linear(in_features=15, out_features=16, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (fc3): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "All the models have been loaded\n"
     ]
    }
   ],
   "source": [
    "rf = joblib.load(\"../models/random_forest.pkl\")\n",
    "gb = joblib.load(\"../models/gradient_boosting.pkl\")\n",
    "ada = joblib.load(\"../models/adaboost.pkl\")\n",
    "\n",
    "# Load the saved model\n",
    "model = CancerNN()\n",
    "model.load_state_dict(torch.load(\"../models/cancer_detector.pth\"))\n",
    "print(model.eval())  # Set to evaluation mode\n",
    "\n",
    "print(\"All the models have been loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Prediction: 1\n",
      "Random Forest Prediction: 1\n",
      "Gradient Boosting Prediction: 1\n",
      "AdaBoost Prediction: 1\n",
      "Ensemble Prediction (Final Decision): 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- ALCOHOL_CONSUMING\n",
      "- ALLERGY\n",
      "- CHEST_PAIN\n",
      "- CHRONIC_DISEASE\n",
      "- FATIGUE\n",
      "- ...\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- ALCOHOL CONSUMING\n",
      "- ALLERGY \n",
      "- CHEST PAIN\n",
      "- CHRONIC DISEASE\n",
      "- FATIGUE \n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "sample_data = pd.DataFrame({\n",
    "    \"GENDER\": [1],  # M -> 1, F -> 0\n",
    "    \"AGE\": [65],\n",
    "    \"SMOKING\": [2],\n",
    "    \"YELLOW_FINGERS\": [1],\n",
    "    \"ANXIETY\": [1],\n",
    "    \"PEER_PRESSURE\": [2],\n",
    "    \"CHRONIC_DISEASE\": [1],\n",
    "    \"FATIGUE\": [2],\n",
    "    \"ALLERGY\": [1],\n",
    "    \"WHEEZING\": [2],\n",
    "    \"ALCOHOL_CONSUMING\": [2],\n",
    "    \"COUGHING\": [1],\n",
    "    \"SHORTNESS_OF_BREATH\": [2],\n",
    "    \"SWALLOWING_DIFFICULTY\": [1],\n",
    "    \"CHEST_PAIN\": [2]\n",
    "})\n",
    "\n",
    "# Normalize input using the saved scaler\n",
    "sample_scaled = scaler.transform(sample_data)\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "sample_tensor = torch.tensor(sample_scaled, dtype=torch.float32)\n",
    "\n",
    "# Predict using Neural Network\n",
    "with torch.no_grad():\n",
    "    nn_prediction = model(sample_tensor).item()\n",
    "    nn_prediction = 1 if nn_prediction > 0.5 else 0  # Convert probability to class\n",
    "\n",
    "# Predict using ML Models\n",
    "rf_pred = rf.predict(sample_scaled)[0]\n",
    "gb_pred = gb.predict(sample_scaled)[0]\n",
    "ada_pred = ada.predict(sample_scaled)[0]\n",
    "\n",
    "# Ensemble (average voting)\n",
    "ensemble_pred = round((rf_pred + gb_pred + ada_pred) / 3)\n",
    "\n",
    "print(f\"Neural Network Prediction: {nn_prediction}\")\n",
    "print(f\"Random Forest Prediction: {rf_pred}\")\n",
    "print(f\"Gradient Boosting Prediction: {gb_pred}\")\n",
    "print(f\"AdaBoost Prediction: {ada_pred}\")\n",
    "print(f\"Ensemble Prediction (Final Decision): {ensemble_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
